{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Extraction for SEMRYE project\n",
    "\n",
    "Extract word pairs of rhymes in poems. Current for the collections of Shakespeare and Housman available in https://github.com/sravanareddy/rhymedata, courtesy of Sravana Reddy.\n",
    "\n",
    "\n",
    "## Output Format\n",
    "\n",
    "Output format would be string tuples: \n",
    "\n",
    "> ( word1:str, word2:str, rhyme pattern:str, rhyme letter:str, poetm title:str, section id:str, author:str)\n",
    "\n",
    "**section id** starts from 0\n",
    "\n",
    "For example,\n",
    "\n",
    "**Input:**\n",
    "\n",
    ">TITLE A Lover's Complaint\n",
    "\n",
    ">RHYME a b a b b c c\n",
    "\n",
    ">From off a hill whose concave womb reworded\n",
    "\n",
    ">A plaintful story from a sistering vale,\n",
    "\n",
    ">My spirits to attend this double voice reworded,\n",
    "\n",
    ">And down I laid to list the sad-tuned tale;\n",
    "\n",
    ">Ere long espied a fickle maid full pale, \n",
    "\n",
    ">Tearing of papers, breaking rings a-twain,\n",
    "\n",
    ">Storming her world with sorrow's wind and rain.\n",
    "\n",
    "> ...\n",
    "\n",
    "For the full scheme of the data, see: https://github.com/sravanareddy/rhymedata\n",
    "\n",
    "** Output:**\n",
    "\n",
    "*(reworded, reworded, ababbcc, a, A Lover's Complaint, 1, Shakespeare )*\n",
    "\n",
    "*(vale, tale, ababbcc, b, A Lover's Complaint, 1,  Shakespeare )*\n",
    "\n",
    "*(vale, pale, ababbcc, b, A Lover's Complaint, 1, Shakespeare )*\n",
    "\n",
    "*(tale, pale, ababbcc, b, A Lover's Complaint, 1, Shakespeare )*\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "** Note0** We may also want to keep a mapping **section_map**\n",
    "- key: triple (poetm title <str>, section id <str>,  author <str>) \n",
    "- value: (section text, rhyme pattern)\n",
    "\n",
    "\n",
    "\n",
    "**Note1** For now, if a rhyme involves multiple words, like the **b** rhyem above, which as 3 words *vale*, *tale*, and *pale*. We extract all the pairs and keep the partial order, i.e.  *(vale, tale)*, *(tale, pale)* and *(vale, pale)* for the example\n",
    "\n",
    "**Note2** a special scheme used in the original data is \n",
    "> Sometimes, we use a shorthand for the rhyme scheme, like \n",
    "\n",
    ">RHYME a a *\n",
    "\n",
    ">This denotes the rhyme scheme aabbccdd...\n",
    "\n",
    "We elaborate such patterns in this case.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Code Design\n",
    "\n",
    "### Format of input data\n",
    "The format of original data is quite regular\n",
    "Each file dedicates to one author, which is specified in the first line\n",
    "\n",
    "**poem structure**:\n",
    ">an empty line\n",
    "\n",
    ">title\n",
    "\n",
    ">sections*\n",
    "\n",
    "**section strucre**:\n",
    "\n",
    ">empty line\n",
    "\n",
    ">rhyme pattern\n",
    "\n",
    ">empty line\n",
    "\n",
    ">poem line*\n",
    "\n",
    "> **UPDATE** It is NOT ture that each section starts with rhyme pattern, consecutive sections may share the same pattern, which is only specified before the 1st section.  See line 734 of Shakespear.txt for example\n",
    "\n",
    "Poem lines are consecutive lines with content.\n",
    "\n",
    "**Rhyme is at the last word of a poem line**\n",
    "\n",
    "\n",
    "### Format of internal data\n",
    "\n",
    "(discarded) **collections**: a list of **poem**, which is a tuple of (**poem title**, **list_of_section**)\n",
    "(discarded) **list_of_section**: a list of **section**, each of which is a tuple (**section id**, **section text**, line_count)\n",
    "\n",
    "#### Two outputs \n",
    "\n",
    "1. **word_pair_list**: a list of word pairs, each of the format **(word1 <str>, word2 <str>, rhyme pattern <str>, rhyme letter <str>, poetm title <str>, section id <str>, author <str> )**\n",
    "\n",
    "2. **section_map**: a dictionary. key: (**poem title**, **section id**)  value: tuple(**section text** <list of list of string, i.e. splitted>, **rhyme pattern** <string>)\n",
    "\n",
    "\n",
    "### Functions\n",
    "Looks like there is no need for internal states offered by class. So the code will be procedure-based.\n",
    "\n",
    "\n",
    "def **poem extract (file_name)**:\n",
    "    1. get the *author_name* string\n",
    "    \n",
    "    loops for finding the poem\n",
    "        get the *poem title*\n",
    "        main *section_count*\n",
    "        \n",
    "        loop for finding sections\n",
    "            get the *rhyme string*\n",
    "            get *section text* and line count\n",
    "            add entry to *section_map*\n",
    "            \n",
    "            call **parse_rhyme_pattern**, get rhyme pattern\n",
    "            call **pair_extraction**, get word pair tuple, insert to *word_pair_list*\n",
    "            \n",
    "\n",
    "    return  word_pair_list, section_map, author_name \n",
    "\n",
    "\n",
    "def **parse_rhyme(rhyme string, line_count)**:\n",
    "    \n",
    "    return  new_rhyme_str, index_pair_list\n",
    "\n",
    "Format of index_pair_list: (index1, index2, rhyme_letter)\n",
    "\n",
    "\n",
    "def **pair_extraction(index_pair_list, section_text)** :\n",
    "    return raw_pair_list\n",
    "    \n",
    "\n",
    "    \n",
    "Format of each pair in raw_pair_list:  (word1, word2, letter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function   # try to be python3 compatible, but it does not always work.\n",
    "import string\n",
    "import codecs #might be useful for dealing with poems in other languages\n",
    "import cPickle as pickle\n",
    "\n",
    "def poem_extract(poem_file):\n",
    "    \n",
    "    # two output data structure\n",
    "    section_map = {}\n",
    "    word_pair_list = []\n",
    "    \n",
    "    debug = False\n",
    "    \n",
    "    #with open(poem_file, 'r') as f: # as it's pure ascii\n",
    "    with codecs.open(poem_file, 'rU','utf-8') as f:  #change to it when handling with non-ascii langauge...\n",
    "        lines = f.readlines()\n",
    "        author_line = lines[0].split()\n",
    "        lines = lines[1:]\n",
    "        \n",
    "    assert author_line[0]== 'AUTHOR'\n",
    "    author_str = \" \".join(author_line[1:])\n",
    "    \n",
    "    seen_text =   False\n",
    "    #seen_rhyme = False\n",
    "    section_text = []\n",
    "    section_count = 0\n",
    "    rhyme, poem_title = None, None\n",
    "    \n",
    "    total_line_count, total_section_count, total_title_count = 0, 0, 0\n",
    "    \n",
    "    for line_id, line in enumerate(lines):\n",
    "        \n",
    "        #print ('line num', line_id+2, ':', line.strip() ) \n",
    "        \n",
    "        if line.split()==[]:\n",
    "            #seen_rhyme = False\n",
    "            if seen_text:\n",
    "                \n",
    "                assert  len(section_text) > 0\n",
    "                assert rhyme\n",
    "                assert poem_title\n",
    "                \n",
    "                total_section_count += 1                \n",
    "              \n",
    "                section_line_count = len(section_text)\n",
    "                rhyme_str, index_pair_list = parse_rhyme(rhyme, section_line_count) # parse rhyme pattern\n",
    "                \n",
    "                section_map[(poem_title, section_count)] = (section_text, rhyme_str) # update section_map\n",
    "                \n",
    "                raw_pair_list = pair_extraction(index_pair_list, section_text) # extract word pairs in the rhyme\n",
    "                \n",
    "                extended_pair_list = [ (word1 , word2 , rhyme_str , rhyme_letter , poem_title , section_count , author_str ) for word1, word2, rhyme_letter in raw_pair_list ]\n",
    "                word_pair_list.extend(extended_pair_list) # update word_pair_list\n",
    "        \n",
    "                if debug:\n",
    "                    for word1, word2, rhyme_letter in raw_pair_list:\n",
    "                        print ('record:', word1, word2, rhyme_letter)\n",
    "        \n",
    "                section_count += 1\n",
    "                section_text = []\n",
    "                section_line_count = 0\n",
    "                \n",
    "                # this logic of following two section does not hold, as line 724 in shakespear, where two consecutive sections with only one rhyme specified\n",
    "                #rhyme = None\n",
    "                #seen_rhyme = False\n",
    "                seen_text = False\n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "        elif line.split()[0] == 'TITLE':\n",
    "            poem_title = \" \".join(line.split()[1:])\n",
    "            #seen_title = True           \n",
    "            total_title_count += 1\n",
    "            section_count = 0\n",
    "            \n",
    "        \n",
    "        #elif  not seen_rhyme:  # the old logic does not hold, as line 724 in shakespear, where two consecutive sections with only one rhyme specified\n",
    "            #assert line.split()[0] == 'RHYME'\n",
    "        elif   line.split()[0] == 'RHYME':   \n",
    "            rhyme = line.split()[1:]\n",
    "            #seen_rhyme = True \n",
    "            if debug: print (rhyme)\n",
    "        \n",
    "        else:\n",
    "            seen_text = True\n",
    "            section_text.append(line.split())\n",
    "            total_line_count += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print ('\\n\\nDone! total line count/section count/title count=', total_line_count, total_section_count, total_title_count)\n",
    "    \n",
    "    return word_pair_list, section_map\n",
    "\n",
    "        \n",
    "            \n",
    "#\n",
    "# auxiliary function to compute the partial ordered pairs from a list of items\n",
    "#\n",
    "def get_partial_order_pair_list(list_of_item):\n",
    "    partial_list = []\n",
    "    if len(list_of_item)== 2:\n",
    "        partial_list.append(tuple(list_of_item))\n",
    "\n",
    "    else:\n",
    "        for i, item in enumerate(list_of_item[:-1]):\n",
    "            for j in range(i+1, len(list_of_item)):\n",
    "                partial_list.append((item, list_of_item[j]))\n",
    "\n",
    "    return partial_list            \n",
    "            \n",
    "\n",
    "def parse_rhyme(rhyme, section_line_count):\n",
    "    if rhyme[-1] == '*':\n",
    "        unit = rhyme[:-1]\n",
    "        assert len(set(unit))==1\n",
    "        base = ord(unit[0])\n",
    "        \n",
    "        assert section_line_count%len(unit) == 0\n",
    "        \n",
    "        repeat = (section_line_count- len(unit))/len(unit)\n",
    "        rhyme =[]\n",
    "        rhyme.extend(unit)\n",
    "        for i in range(repeat):\n",
    "            for j in range(len(unit)):\n",
    "                rhyme.append(chr(base+i+1))\n",
    "    \n",
    "    assert len(rhyme) == section_line_count\n",
    "    \n",
    "    letter2index = {}\n",
    "    for i, letter in enumerate(rhyme):\n",
    "        letter2index.setdefault(letter, []).append(i)\n",
    "    #return letter2index\n",
    "    \n",
    "    #Format of index_pair_list: (index1, index2, rhyme_letter)\n",
    "    index_pair_list= []\n",
    "    \n",
    "    for rhyme_letter in letter2index:\n",
    "        index_list = letter2index[rhyme_letter]\n",
    "        partial_list = get_partial_order_pair_list(index_list)\n",
    "\n",
    "        for pair in partial_list:\n",
    "            index1, index2 = pair\n",
    "            index_pair_list.append((index1, index2, rhyme_letter))\n",
    "\n",
    "\n",
    "    index_pair_list.sort() \n",
    "    new_rhyme_str = ''.join(rhyme)\n",
    "\n",
    "    return new_rhyme_str, index_pair_list\n",
    "\n",
    "\n",
    "def remove_tail_punctuation(word):\n",
    "    last = len(word)\n",
    "    for i in range(last, 0, -1):\n",
    "        #print (word[i-1: i])\n",
    "        if word[i-1: i] not in string.punctuation:\n",
    "            break\n",
    "    return word[:i]\n",
    "\n",
    "\n",
    "def pair_extraction(index_pair_list, section_text):\n",
    "    \n",
    "    debug = False\n",
    "    # section_text are list of words (str)\n",
    "    \n",
    "    raw_pair_list = []\n",
    "    #Format of each pair in raw_pair_list: (word1, word2, letter)\n",
    "    \n",
    "    list_of_last_word = [remove_tail_punctuation(sent[-1]) for sent in section_text]\n",
    "    \n",
    "\n",
    "    if debug: print ('list of last_word', list_of_last_word)\n",
    "    \n",
    "    for index1, index2, rhyme_letter in index_pair_list:\n",
    "        raw_pair_list.append( (list_of_last_word[index1], list_of_last_word[index2], rhyme_letter))\n",
    "    \n",
    "    \n",
    "    return raw_pair_list\n",
    "\n",
    "    \n",
    "from nltk import word_tokenize\n",
    "def get_word_list(section_map):\n",
    "    list_of_text_rhyme = section_map.values()\n",
    "    section_text_list, _ = zip(* list_of_text_rhyme)    \n",
    "    list_of_sent = []\n",
    "    for sec in section_text_list:\n",
    "        for line in sec:\n",
    "            list_of_sent.append(line)\n",
    "            \n",
    "    list_str_sent = [\" \".join(sent) for sent in list_of_sent]\n",
    "    list_tokenized_sent = map(word_tokenize, list_str_sent)\n",
    "    \n",
    "    tmp=[]\n",
    "    for sent in list_tokenized_sent:\n",
    "        s1 = map(remove_tail_punctuation, sent)\n",
    "        s2 = map(lambda x:x.lower(), s1)\n",
    "        tmp.append(s2)\n",
    "        \n",
    "    list_tokenized_sent = tmp\n",
    "    \n",
    "    print (len(list_of_sent), len(list_tokenized_sent),list_of_sent==list_tokenized_sent)\n",
    "    \n",
    "    for i, sent in enumerate(list_of_sent):\n",
    "        if sent!=list_tokenized_sent[i]:\n",
    "            print ('line i before:', sent, ' after:',list_tokenized_sent[i] )\n",
    "            break\n",
    " \n",
    "    word_set =set()\n",
    "    for sent in list_tokenized_sent:\n",
    "        word_set.update(sent)\n",
    "    \n",
    "    print ('num of word type extracted:', len(word_set))\n",
    "    return word_set    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample partial list =  [(1, 3), (1, 4), (3, 4)]\n",
      "('ababbcc', [(0, 2, 'a'), (1, 3, 'b'), (1, 4, 'b'), (3, 4, 'b'), (5, 6, 'c')]) ('aabbccdd', [(0, 1, 'a'), (2, 3, 'b'), (4, 5, 'c'), (6, 7, 'd')])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# UNIT TEST for parse_rhyme()\n",
    "#\n",
    "\n",
    "r=get_partial_order_pair_list([1, 3, 4])\n",
    "print ('sample partial list = ', r)\n",
    "\n",
    "\n",
    "a=parse_rhyme('a b a b b c c'.split(), 7)\n",
    "b=parse_rhyme('a a *'.split(), 8)\n",
    "print (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['From', 'off', 'a', 'hill', 'whose', 'concave', 'womb', 'reworded'], ['A', 'plaintful', 'story', 'from', 'a', 'sistering', 'vale,'], ['My', 'spirits', 'to', 'attend', 'this', 'double', 'voice', 'accorded,'], ['And', 'down', 'I', 'laid', 'to', 'list', 'the', 'sad-tuned', 'tale;'], ['Ere', 'long', 'espied', 'a', 'fickle', 'maid', 'full', 'pale,'], ['Tearing', 'of', 'papers,', 'breaking', 'rings', 'a-twain,'], ['Storming', 'her', 'world', 'with', \"sorrow's\", 'wind', 'and', 'rain.']]\n",
      "index_pair_list: [(0, 2, 'a'), (1, 3, 'b'), (1, 4, 'b'), (3, 4, 'b'), (5, 6, 'c')]\n",
      "\n",
      "Raw pair list:\n",
      "('reworded', 'accorded', 'a')\n",
      "('vale', 'tale', 'b')\n",
      "('vale', 'pale', 'b')\n",
      "('tale', 'pale', 'b')\n",
      "('a-twain', 'rain', 'c')\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# UNIT TEST for pair_extraction() \n",
    "#\n",
    "\n",
    "section_text = '''From off a hill whose concave womb reworded\n",
    "A plaintful story from a sistering vale,\n",
    "My spirits to attend this double voice accorded,\n",
    "And down I laid to list the sad-tuned tale;\n",
    "Ere long espied a fickle maid full pale, \n",
    "Tearing of papers, breaking rings a-twain,\n",
    "Storming her world with sorrow's wind and rain.\n",
    "'''\n",
    "\n",
    "with open('tmp','w') as f:\n",
    "    f.write(section_text)\n",
    "\n",
    "with open('tmp','r') as f:\n",
    "    text = f.readlines()\n",
    "    section_text = [l.split() for l in text]\n",
    "print (section_text)\n",
    "\n",
    "\n",
    "new_rhyme_str, index_pair_list = parse_rhyme ('a b a b b c c'.split() ,7)\n",
    "print ('index_pair_list:', index_pair_list)\n",
    "\n",
    "raw_pair_list = pair_extraction(index_pair_list, section_text)\n",
    "\n",
    "print ('\\nRaw pair list:')\n",
    "for i in raw_pair_list:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Done! total line count/section count/title count= 5949 722 24\n",
      "Word pair list have been pickled to  ../working_data/shakes.pair.pkl\n",
      "Section map have been pickled to  ../working_data/shakes.map.pkl\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Run the whole program for Shakespear\n",
    "#\n",
    "path_shake = '../data/shakespeare.txt'\n",
    "word_pair_list_shakes, section_map_shakes =  poem_extract(path_shake)\n",
    "\n",
    "wp_path_s = '../working_data/shakes.pair.pkl'\n",
    "sm_path_s = '../working_data/shakes.map.pkl'\n",
    "\n",
    "with open(wp_path_s, 'wb') as f:\n",
    "    pickle.dump(word_pair_list_shakes, f)\n",
    "print ('Word pair list have been pickled to ', wp_path_s)\n",
    "\n",
    "with open(sm_path_s, 'wb') as f:\n",
    "    pickle.dump(section_map_shakes, f)\n",
    "print ('Section map have been pickled to ', sm_path_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'reworded', u'accorded', u'ababbcc', u'a', u\"A Lover's Complaint\", 0, u'William Shakespeare')\n",
      "(u'vale', u'tale', u'ababbcc', u'b', u\"A Lover's Complaint\", 0, u'William Shakespeare')\n",
      "(u'vale', u'pale', u'ababbcc', u'b', u\"A Lover's Complaint\", 0, u'William Shakespeare')\n",
      "(u'tale', u'pale', u'ababbcc', u'b', u\"A Lover's Complaint\", 0, u'William Shakespeare')\n",
      "(u'a-twain', u'rain', u'ababbcc', u'c', u\"A Lover's Complaint\", 0, u'William Shakespeare')\n",
      "(u'straw', u'saw', u'ababbcc', u'a', u\"A Lover's Complaint\", 1, u'William Shakespeare')\n",
      "(u'sun', u'done', u'ababbcc', u'b', u\"A Lover's Complaint\", 1, u'William Shakespeare')\n",
      "(u'sun', u'begun', u'ababbcc', u'b', u\"A Lover's Complaint\", 1, u'William Shakespeare')\n",
      "(u'done', u'begun', u'ababbcc', u'b', u\"A Lover's Complaint\", 1, u'William Shakespeare')\n",
      "(u'rage', u'age', u'ababbcc', u'c', u\"A Lover's Complaint\", 1, u'William Shakespeare')\n",
      "(u'eyne', u'brine', u'ababbcc', u'a', u\"A Lover's Complaint\", 2, u'William Shakespeare')\n",
      "(u'characters', u'tears', u'ababbcc', u'b', u\"A Lover's Complaint\", 2, u'William Shakespeare')\n",
      "(u'characters', u'bears', u'ababbcc', u'b', u\"A Lover's Complaint\", 2, u'William Shakespeare')\n",
      "(u'tears', u'bears', u'ababbcc', u'b', u\"A Lover's Complaint\", 2, u'William Shakespeare')\n",
      "(u'woe', u'low', u'ababbcc', u'c', u\"A Lover's Complaint\", 2, u'William Shakespeare')\n",
      "(u'ride', u'tied', u'ababbcc', u'a', u\"A Lover's Complaint\", 3, u'William Shakespeare')\n",
      "(u'intend', u'extend', u'ababbcc', u'b', u\"A Lover's Complaint\", 3, u'William Shakespeare')\n",
      "(u'intend', u'lend', u'ababbcc', u'b', u\"A Lover's Complaint\", 3, u'William Shakespeare')\n",
      "(u'extend', u'lend', u'ababbcc', u'b', u\"A Lover's Complaint\", 3, u'William Shakespeare')\n",
      "(u\"fix'd\", u\"commix'd\", u'ababbcc', u'c', u\"A Lover's Complaint\", 3, u'William Shakespeare')\n",
      "(u'The Rape of Lucrece', 200) : ([[u'There', u'pleading', u'might', u'you', u'see', u'grave', u'Nestor', u'stand,'], [u'As', u\"'twere\", u'encouraging', u'the', u'Greeks', u'to', u'fight;'], [u'Making', u'such', u'sober', u'action', u'with', u'his', u'hand,'], [u'That', u'it', u'beguiled', u'attention,', u\"charm'd\", u'the', u'sight:'], [u'In', u'speech,', u'it', u\"seem'd,\", u'his', u'beard,', u'all', u'silver', u'white,'], [u\"Wagg'd\", u'up', u'and', u'down,', u'and', u'from', u'his', u'lips', u'did', u'fly'], [u'Thin', u'winding', u'breath,', u'which', u\"purl'd\", u'up', u'to', u'the', u'sky.']], u'ababbcc')\n",
      "(u'Sonnets', 86) : ([[u'farewell', u'thou', u'art', u'too', u'dear', u'for', u'my', u'possessing'], [u'and', u'like', u'enough', u'thou', u'knowst', u'thy', u'estimate'], [u'the', u'charter', u'of', u'thy', u'worth', u'gives', u'thee', u'releasing'], [u'my', u'bonds', u'in', u'thee', u'are', u'all', u'determinate'], [u'for', u'how', u'do', u'i', u'hold', u'thee', u'but', u'by', u'thy', u'granting'], [u'and', u'for', u'that', u'riches', u'where', u'is', u'my', u'deserving'], [u'the', u'cause', u'of', u'this', u'fair', u'gift', u'in', u'me', u'is', u'wanting'], [u'and', u'so', u'my', u'patent', u'back', u'again', u'is', u'swerving'], [u'thyself', u'thou', u'gavest', u'thy', u'own', u'worth', u'then', u'not', u'knowing'], [u'or', u'me', u'to', u'whom', u'thou', u'gavest', u'it', u'else', u'mistaking'], [u'so', u'thy', u'great', u'gift', u'upon', u'misprision', u'growing'], [u'comes', u'home', u'again', u'on', u'better', u'judgment', u'making'], [u'thus', u'have', u'i', u'had', u'thee', u'as', u'a', u'dream', u'doth', u'flatter'], [u'in', u'sleep', u'a', u'king', u'but', u'waking', u'no', u'such', u'matter']], u'ababcdcdefefgg')\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Inspect the results for Shakespear\n",
    "#\n",
    "\n",
    "for i in word_pair_list_shakes [:20]:\n",
    "    print (i)\n",
    "\n",
    "k_list = section_map_shakes.keys()[8:10]\n",
    "for k in k_list:\n",
    "    print (k, ':', section_map_shakes[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Done! total line count/section count/title count= 3215 659 177\n",
      "Word pair list have been pickled to  ../working_data/housman.pair.pkl\n",
      "Section map have been pickled to  ../working_data/housman.map.pkl\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Run the whole program Housman\n",
    "#\n",
    "\n",
    "path_shake = '../data/housman.txt'\n",
    "word_pair_list_housman, section_map_housman =  poem_extract(path_shake)\n",
    "\n",
    "wp_path = '../working_data/housman.pair.pkl'\n",
    "sm_path = '../working_data/housman.map.pkl'\n",
    "\n",
    "with open(wp_path, 'wb') as f:\n",
    "    pickle.dump(word_pair_list_housman, f)\n",
    "print ('Word pair list have been pickled to ', wp_path)\n",
    "\n",
    "with open(sm_path, 'wb') as f:\n",
    "    pickle.dump(section_map_housman, f)\n",
    "print ('Section map have been pickled to ', sm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakespeare: 30.0833333333 8.23961218837\n",
      "housman 3.72316384181 4.87860394537\n",
      "(u'reworded', u'accorded', u'ababbcc', u'a', u\"A Lover's Complaint\", 0, u'William Shakespeare')\n",
      "(u'vale', u'tale', u'ababbcc', u'b', u\"A Lover's Complaint\", 0, u'William Shakespeare')\n",
      "(u'vale', u'pale', u'ababbcc', u'b', u\"A Lover's Complaint\", 0, u'William Shakespeare')\n",
      "(u'tale', u'pale', u'ababbcc', u'b', u\"A Lover's Complaint\", 0, u'William Shakespeare')\n",
      "(u'a-twain', u'rain', u'ababbcc', u'c', u\"A Lover's Complaint\", 0, u'William Shakespeare')\n",
      "(u'straw', u'saw', u'ababbcc', u'a', u\"A Lover's Complaint\", 1, u'William Shakespeare')\n",
      "(u'sun', u'done', u'ababbcc', u'b', u\"A Lover's Complaint\", 1, u'William Shakespeare')\n",
      "(u'sun', u'begun', u'ababbcc', u'b', u\"A Lover's Complaint\", 1, u'William Shakespeare')\n",
      "(u'done', u'begun', u'ababbcc', u'b', u\"A Lover's Complaint\", 1, u'William Shakespeare')\n",
      "(u'rage', u'age', u'ababbcc', u'c', u\"A Lover's Complaint\", 1, u'William Shakespeare')\n",
      "(u'eyne', u'brine', u'ababbcc', u'a', u\"A Lover's Complaint\", 2, u'William Shakespeare')\n",
      "(u'characters', u'tears', u'ababbcc', u'b', u\"A Lover's Complaint\", 2, u'William Shakespeare')\n",
      "(u'characters', u'bears', u'ababbcc', u'b', u\"A Lover's Complaint\", 2, u'William Shakespeare')\n",
      "(u'tears', u'bears', u'ababbcc', u'b', u\"A Lover's Complaint\", 2, u'William Shakespeare')\n",
      "(u'woe', u'low', u'ababbcc', u'c', u\"A Lover's Complaint\", 2, u'William Shakespeare')\n",
      "(u'ride', u'tied', u'ababbcc', u'a', u\"A Lover's Complaint\", 3, u'William Shakespeare')\n",
      "(u'intend', u'extend', u'ababbcc', u'b', u\"A Lover's Complaint\", 3, u'William Shakespeare')\n",
      "(u'intend', u'lend', u'ababbcc', u'b', u\"A Lover's Complaint\", 3, u'William Shakespeare')\n",
      "(u'extend', u'lend', u'ababbcc', u'b', u\"A Lover's Complaint\", 3, u'William Shakespeare')\n",
      "(u\"fix'd\", u\"commix'd\", u'ababbcc', u'c', u\"A Lover's Complaint\", 3, u'William Shakespeare')\n",
      "5949 5949 False\n",
      "line i before: [u\"'Hast\", u'thou', u'command?', u'by', u'him', u'that', u'gave', u'it', u'thee,']  after: [u\"'hast\", u'thou', u'command', u'?', u'by', u'him', u'that', u'gave', u'it', u'thee']\n",
      "num of word type extracted: 6658\n",
      "3199 3199 False\n",
      "line i before: [u'Their', u'voices,', u'dying', u'as', u'they', u'fly,']  after: [u'their', u'voices', u',', u'dying', u'as', u'they', u'fly']\n",
      "num of word type extracted: 3390\n",
      "num of word types in Shakes and Housman 6658 3390\n",
      "Vocab files have been pickled to  ../working_data/shakes.voc.pkl ../working_data/housman.voc.pkl , respectively\n",
      "size of loaded vocab file 6658 3390\n",
      "size of intersection/union 1773 8275\n",
      "sampled 20 words that appear in housman but not in shakespear\n",
      "death-notes\n",
      "sestos\n",
      "straws\n",
      "rampart\n",
      "yonder\n",
      "adorning\n",
      "snowing\n",
      "sunlit\n",
      "fists\n",
      "conjecture\n",
      "wreath\n",
      "blanket\n",
      "oceans\n",
      "weald\n",
      "knelt\n",
      "smack\n",
      "stolen\n",
      "screaming\n",
      "laurels\n",
      "withers\n"
     ]
    }
   ],
   "source": [
    "# shakespeare writes way more sections per poem and more lines per sections...\n",
    "print ('shakespeare:',722/24.0, 5949/722.0)\n",
    "print ('housman',659/177.0, 3215/659.0)\n",
    "\n",
    "\n",
    "# import shakespeare pickles...\n",
    "word_pair_shakes = pickle.load(open('../working_data/shakes.pair.pkl', 'rb'))\n",
    "for i in word_pair_shakes [:20]:\n",
    "    print (i)\n",
    "\n",
    "\n",
    "#\n",
    "#extract word list\n",
    "#\n",
    "\n",
    "word_shakes = get_word_list(section_map_shakes)\n",
    "word_housman = get_word_list(section_map_housman)\n",
    "\n",
    "print ('num of word types in Shakes and Housman', len(word_shakes), len(word_housman))\n",
    "\n",
    "word_shakes_path, word_housman_path = '../working_data/shakes.voc.pkl', '../working_data/housman.voc.pkl'\n",
    "with open(word_shakes_path, 'wb') as f:\n",
    "    pickle.dump(word_shakes,f)\n",
    "with open(word_housman_path, 'wb') as f:\n",
    "    pickle.dump(word_housman,f)\n",
    "\n",
    "print ('Vocab files have been pickled to ', word_shakes_path, word_housman_path, ', respectively')\n",
    "\n",
    "with open(word_shakes_path, 'rb') as f:\n",
    "    s = pickle.load(f)\n",
    "\n",
    "with open(word_housman_path, 'rb') as f:\n",
    "    h = pickle.load(f)\n",
    "\n",
    "print ('size of loaded vocab file', len(s), len(h))\n",
    "print ('size of intersection/union', len(s.intersection(h)), len(s.union(h)))\n",
    "d = list(h.difference(s))\n",
    "print ('sampled 20 words that appear in housman but not in shakespear')\n",
    "for i in d[:20]:\n",
    "    print (i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with embeddings requires Dissect (https://github.com/composes-toolkit/dissect). We use the 'dense' format, which requires the embeddings in the format [word numeric representation]. We use the 300-dimensional pre-trained GloVe embeddings from http://nlp.stanford.edu/projects/glove/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> loading embeddings from ../data/embeddings/glove.6B.300d_dense.emb\n",
      "==> loaded.\n"
     ]
    }
   ],
   "source": [
    "# load embedding space\n",
    "from composes.semantic_space.space import Space\n",
    "glove_embeddings_file = '../data/embeddings/glove.6B.300d_dense.emb'\n",
    "print(\"==> loading embeddings from \" + glove_embeddings_file)\n",
    "glove_word_space = Space.build(data=glove_embeddings_file, format='dm')\n",
    "print(\"==> loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the embeddings for the selected word pairs\n",
    "def extract_embeddings(embeddings_space, word_pairs):\n",
    "    word_list = embeddings_space.get_id2row()\n",
    "    existing_pairs_list = []\n",
    "    for wp in word_pairs:\n",
    "        if wp[0].encode('utf8') in word_list:\n",
    "            w1_emb = embeddings_space.get_row(wp[0]).mat\n",
    "            if wp[1].encode('utf8') in word_list:\n",
    "                w2_emb = embeddings_space.get_row(wp[1]).mat\n",
    "                \n",
    "                #both words exist, append them to the 'existing' list\n",
    "                new_wp = list(wp)\n",
    "                new_wp.append(w1_emb)\n",
    "                new_wp.append(w2_emb)\n",
    "                new_wp_tuple = tuple(new_wp)\n",
    "                existing_pairs_list.append(new_wp_tuple)\n",
    "                \n",
    "    print(\"==> \"+ str(len(existing_pairs_list)) +\" representations found out of \" + str(len(word_pairs)))\n",
    "    return existing_pairs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 3147 representations found out of 3454\n",
      "Word pair list with representations have been pickled to  ../working_data/shakes.pair.glove.pkl\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "# extract GloVe representations for the Shakespeare data\n",
    "word_pair_shakes = pickle.load(open('../working_data/shakes.pair.pkl', 'rb'))\n",
    "glove_shakespeare_wp = extract_embeddings(glove_word_space, word_pair_shakes)\n",
    "glove_shakespeare_wp_path = '../working_data/shakes.pair.glove.pkl'\n",
    "\n",
    "with open(glove_shakespeare_wp_path, 'wb') as f:\n",
    "    pickle.dump(glove_shakespeare_wp, f)\n",
    "print ('Word pair list with representations have been pickled to ', glove_shakespeare_wp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 1407 representations found out of 1548\n",
      "Word pair list with representations have been pickled to  ../working_data/housman.pair.glove.pkl\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "# extract GloVe representations for the Housman data\n",
    "word_pair_housman = pickle.load(open('../working_data/housman.pair.pkl', 'rb'))\n",
    "glove_housman_wp = extract_embeddings(glove_word_space, word_pair_housman)\n",
    "glove_housman_wp_path = '../working_data/housman.pair.glove.pkl'\n",
    "\n",
    "with open(glove_housman_wp_path, 'wb') as f:\n",
    "    pickle.dump(glove_housman_wp, f)\n",
    "print ('Word pair list with representations have been pickled to ', glove_housman_wp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
